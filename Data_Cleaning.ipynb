{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Flight Delay Project - Data Cleaning\n",
    "- The goal of this project is to show relevant data science skills using data from US Domestic flights.\n",
    "\n",
    "- This first notebook will be focused on data cleaning, data engineering, and data preparation\n",
    "\n",
    "- Future notebooks will use this dataset to engage in exploratory data analysis, and predict the delay of flights by tuning machine learning algorithms\n",
    "\n",
    "### The Aim of This Notebook Is To:\n",
    "\n",
    "- Preprocess the dataset to prepare for data analysis and machine learning.\n",
    "- Clean and repair the heterogeneous airport identifiers.\n",
    "- Clean and standardise the time-related columns to ensure that they are machine friendly."
   ],
   "id": "c7e1ed1b25776dc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Import the Dataset",
   "id": "b83e76cc37070e6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:17:42.756824Z",
     "start_time": "2025-05-14T15:17:42.741926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "ccc5fed5cfae2c2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:17:56.573072Z",
     "start_time": "2025-05-14T15:17:42.906038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# airlines_df includes information about each airline\n",
    "airlines_df = pd.read_csv(\"data/airlines.csv\")\n",
    "\n",
    "# airports_df includes information about each airport\n",
    "airports_df = pd.read_csv(\"data/airports.csv\")\n",
    "\n",
    "# flights_df includes information about each flight and will be the primary dataframe in this project.\n",
    "flights_df = pd.read_csv(\"data/flights.csv\",\n",
    "                         dtype={\"YEAR\":\"category\",\n",
    "                                \"MONTH\":\"uint8\",\n",
    "                                \"DAY\":\"uint8\",\n",
    "                                \"DAY_OF_WEEK\":\"uint8\",\n",
    "                                \"AIRLINE\":\"category\",\n",
    "                                \"FLIGHT_NUMBER\":\"category\",\n",
    "                                \"TAIL_NUMBER\":\"category\",\n",
    "                                \"ORIGIN_AIRPORT\":\"str\",\n",
    "                                \"DESTINATION_AIRPORT\":\"str\",\n",
    "                                \"SCHEDULED_DEPARTURE\":\"uint16\",\n",
    "                                \"SCHEDULED_ARRIVAL\":\"uint16\",\n",
    "                                \"DIVERTED\":\"int8\",\n",
    "                                \"CANCELLED\":\"int8\"})\n",
    "\n",
    "print(f\"flights_df is the main dataframe with {flights_df.shape[1]} features and {flights_df.shape[0]:,} rows.  Each row is a flight\")"
   ],
   "id": "481ba284f42eee2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights_df is the main dataframe with 31 features and 5,819,079 rows.  Each row is a flight\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:17:56.676060Z",
     "start_time": "2025-05-14T15:17:56.636641Z"
    }
   },
   "cell_type": "code",
   "source": "flights_df.head()",
   "id": "64409a349ec1591c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0  2015      1    1            4      AS            98      N407AS   \n",
       "1  2015      1    1            4      AA          2336      N3KUAA   \n",
       "2  2015      1    1            4      US           840      N171US   \n",
       "3  2015      1    1            4      AA           258      N3HYAA   \n",
       "4  2015      1    1            4      AS           135      N527AS   \n",
       "\n",
       "  ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  ARRIVAL_TIME  \\\n",
       "0            ANC                 SEA                    5  ...         408.0   \n",
       "1            LAX                 PBI                   10  ...         741.0   \n",
       "2            SFO                 CLT                   20  ...         811.0   \n",
       "3            LAX                 MIA                   20  ...         756.0   \n",
       "4            SEA                 ANC                   25  ...         259.0   \n",
       "\n",
       "   ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "0          -22.0         0          0                  NaN               NaN   \n",
       "1           -9.0         0          0                  NaN               NaN   \n",
       "2            5.0         0          0                  NaN               NaN   \n",
       "3           -9.0         0          0                  NaN               NaN   \n",
       "4          -21.0         0          0                  NaN               NaN   \n",
       "\n",
       "   SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \n",
       "0             NaN            NaN                  NaN            NaN  \n",
       "1             NaN            NaN                  NaN            NaN  \n",
       "2             NaN            NaN                  NaN            NaN  \n",
       "3             NaN            NaN                  NaN            NaN  \n",
       "4             NaN            NaN                  NaN            NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>98</td>\n",
       "      <td>N407AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2336</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>PBI</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>840</td>\n",
       "      <td>N171US</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CLT</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>811.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>258</td>\n",
       "      <td>N3HYAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>135</td>\n",
       "      <td>N527AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 2: Heterogeneous Identifiers\n",
    "The main issue with the dataset is in the columns \"ORIGIN_AIRPORT\", and \"DESTINATION_AIRPORT\".  The majority of the elements are the Airport IATA Codes.  These are the 3 digit codes you can see in the head of the dataframe.  However, all of the elements for the month of October have a different identifier which is a numeric 5-digit code.\n",
    "\n",
    "After some research I was able to find information about these codes.  They are internal identifiers used by US Department of Transportation (DOT).  I downloaded their database of these codes, however, their database does not include the corresponding IATA codes in flights_df (which _is from_ the US DOT but was uploaded in 2015).\n",
    "\n",
    "How to download.  Go to:<br>\n",
    "https://transtats.bts.gov/Fields.asp?gnoyr_VQ=FIL and click on: \"OriginAirportID\".  Unfortunately the direct link to the data is changed regularly.\n",
    "\n",
    "I will replace the 5 digit DOT codes, in flights_df, with the 3 character IATA codes by matching the airports from the DOT database and the flights_df."
   ],
   "id": "b1e6019510fdb05d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Preparing the Data:\n",
    "I will first clean and prepare both airports_df (part of my original dataset) and numeric_airports_df (the new dataframe for the DOT codes) in order to match up the airports."
   ],
   "id": "3abbd3a88a88ddc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:17:59.678824Z",
     "start_time": "2025-05-14T15:17:56.850616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of all flights that depart from an airport with a\n",
    "numeric_flights_df = flights_df[flights_df[\"ORIGIN_AIRPORT\"].str.contains(r\"\\d+\", regex=True)]\n",
    "\n",
    "print(f\"Number of flights in October: {len(flights_df[flights_df['MONTH'] == 10]):,}\")\n",
    "print(f\"Number of October flights with a numeric code: {numeric_flights_df['MONTH'].value_counts().loc[10]:,}\")\n",
    "print(f\"Number of flights with a numeric code in flights_df {len(numeric_flights_df):,}\")"
   ],
   "id": "2a729355ea7c9b3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flights in October: 486,165\n",
      "Number of October flights with a numeric code: 486,165\n",
      "Number of flights with a numeric code in flights_df 486,165\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:17:59.835758Z",
     "start_time": "2025-05-14T15:17:59.805759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reading in the DOT data as numeric_airports_df\n",
    "numeric_airports_df = pd.read_csv(\"data/L_AIRPORT_ID.csv\")\n",
    "numeric_airports_df.head()"
   ],
   "id": "8687b9311f14654f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Code                                    Description\n",
       "0  10001         Afognak Lake, AK: Afognak Lake Airport\n",
       "1  10003  Granite Mountain, AK: Bear Creek Mining Strip\n",
       "2  10004                       Lik, AK: Lik Mining Camp\n",
       "3  10005         Little Squaw, AK: Little Squaw Airport\n",
       "4  10006                     Kizhuyak, AK: Kizhuyak Bay"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>Afognak Lake, AK: Afognak Lake Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003</td>\n",
       "      <td>Granite Mountain, AK: Bear Creek Mining Strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>Lik, AK: Lik Mining Camp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>Little Squaw, AK: Little Squaw Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006</td>\n",
       "      <td>Kizhuyak, AK: Kizhuyak Bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.056621Z",
     "start_time": "2025-05-14T15:17:59.981332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a list of all the DOT codes in the dataset.\n",
    "codes = (pd.concat([numeric_flights_df[\"ORIGIN_AIRPORT\"],\n",
    "                    numeric_flights_df[\"DESTINATION_AIRPORT\"]],\n",
    "                   ignore_index=True)\n",
    "         .unique()\n",
    "         .astype(\"int64\"))\n",
    "\n",
    "# Filter numeric_airports_df to only include the DOT codes that are in the flights_df dataset.\n",
    "numeric_airports_df = numeric_airports_df.set_index(\"Code\").loc[codes].reset_index()\n",
    "\n",
    "print(\"Number of airports in the month of October:\", len(numeric_airports_df))\n",
    "print(\"Number of airports in the dataset as a whole:\", len(airports_df))\n",
    "print(f\"There are {len(airports_df) -len(numeric_airports_df)} less airports used in October than in the rest of the year.\")"
   ],
   "id": "5ebb68b5a3c2e9a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of airports in the month of October: 307\n",
      "Number of airports in the dataset as a whole: 322\n",
      "There are 15 less airports used in October than in the rest of the year.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.210640Z",
     "start_time": "2025-05-14T15:18:00.182101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_airports_df[\"Code\"] = numeric_airports_df[\"Code\"].astype(\"str\")\n",
    "\n",
    "# Extracting derivative columns from the \"Description\" column in numeric_airports_df.\n",
    "numeric_airports_df[\"N_CITY\"] = numeric_airports_df[\"Description\"].str.split(\",\").str[0] # Derivative column for the City\n",
    "numeric_airports_df[\"AIRPORT\"] = numeric_airports_df[\"Description\"].str.split(\": \").str[1] # Derivative column for the Airport name\n",
    "numeric_airports_df[\"N_STATE\"] = numeric_airports_df[\"Description\"].str.extract(r\", (.+?):\") # Derivative column for the State\n",
    "\n",
    "# Strip white space from the derivative columns.\n",
    "for c in [\"N_CITY\", \"AIRPORT\", \"N_STATE\"]:\n",
    "    numeric_airports_df[c].str.strip()\n",
    "\n",
    "numeric_airports_df.head()"
   ],
   "id": "5ae48d8c5e998039",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Code                                       Description          N_CITY  \\\n",
       "0  14747         Seattle, WA: Seattle/Tacoma International         Seattle   \n",
       "1  14771    San Francisco, CA: San Francisco International   San Francisco   \n",
       "2  12889           Las Vegas, NV: Harry Reid International       Las Vegas   \n",
       "3  12892        Los Angeles, CA: Los Angeles International     Los Angeles   \n",
       "4  14869  Salt Lake City, UT: Salt Lake City International  Salt Lake City   \n",
       "\n",
       "                        AIRPORT N_STATE  \n",
       "0  Seattle/Tacoma International      WA  \n",
       "1   San Francisco International      CA  \n",
       "2      Harry Reid International      NV  \n",
       "3     Los Angeles International      CA  \n",
       "4  Salt Lake City International      UT  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>N_CITY</th>\n",
       "      <th>AIRPORT</th>\n",
       "      <th>N_STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14747</td>\n",
       "      <td>Seattle, WA: Seattle/Tacoma International</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Seattle/Tacoma International</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14771</td>\n",
       "      <td>San Francisco, CA: San Francisco International</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco International</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12889</td>\n",
       "      <td>Las Vegas, NV: Harry Reid International</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Harry Reid International</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12892</td>\n",
       "      <td>Los Angeles, CA: Los Angeles International</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles International</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14869</td>\n",
       "      <td>Salt Lake City, UT: Salt Lake City International</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Salt Lake City International</td>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.322152Z",
     "start_time": "2025-05-14T15:18:00.308240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cleaning airports_df\n",
    "airports_df[\"AIRPORT\"] = airports_df[\"AIRPORT\"].str.replace(\"\\u00A0\", \"\") # Get rid of all non-breaking spaces\n",
    "airports_df[\"AIRPORT\"] = airports_df[\"AIRPORT\"].str.replace(\"Airport\", \"\").str.strip() # Remove the word \"Airport\" to match with numeric_airports_df because \"Airport\" is rarely included in numeric_airports_df"
   ],
   "id": "eb82e9ceff13d16e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Matching the Airports:\n",
    "Now I will merge the 2 dataframes together in order to match airports with the same name."
   ],
   "id": "9302805cf2cfd211"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.445948Z",
     "start_time": "2025-05-14T15:18:00.416738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Match airports based off of their names.\n",
    "numeric_airports_df = pd.merge(numeric_airports_df, airports_df, on=\"AIRPORT\", how=\"left\")\n",
    "matched_airports_df = numeric_airports_df.dropna()[[\"Code\", \"IATA_CODE\"]]\n",
    "\n",
    "# Storing the unmatched airports that have numeric DOT codes.\n",
    "unmatched_numeric_airports_df = numeric_airports_df.loc[numeric_airports_df[\"LATITUDE\"].isna(), [\"Code\", \"Description\", \"N_CITY\", \"AIRPORT\", \"N_STATE\"]]\n",
    "\n",
    "# Storing the unmatched airports that have IATA codes.\n",
    "unmatched_airports_df = airports_df[~airports_df[\"IATA_CODE\"].isin(matched_airports_df[\"IATA_CODE\"].to_list())]\n",
    "\n",
    "print(\"Number of matched airports:\", len(matched_airports_df))\n",
    "print(\"Number of unmatched airports from the month of October:\", len(unmatched_numeric_airports_df))\n",
    "print(\"Number of unmatched airports from the dataset as a whole:\", len(unmatched_airports_df))"
   ],
   "id": "942a4c88d9f8d740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched airports: 181\n",
      "Number of unmatched airports from the month of October: 126\n",
      "Number of unmatched airports from the dataset as a whole: 141\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I will now match airports together if they are the only airport in their city.",
   "id": "f1965f349cf560a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.571403Z",
     "start_time": "2025-05-14T15:18:00.542168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gather how many times each city occurs in both dataframes.\n",
    "unmatched_numeric_cities = unmatched_numeric_airports_df[\"N_CITY\"].value_counts()\n",
    "unmatched_cities = unmatched_airports_df[\"CITY\"].value_counts()\n",
    "\n",
    "# Finding when the city occurs only once in both unmatched_numeric_airports_df (DOT) and unmatched_airports_df (IATA).\n",
    "by_city_airports_df =  pd.merge(unmatched_numeric_airports_df.set_index(\"N_CITY\").loc[unmatched_numeric_cities[unmatched_numeric_cities ==1].index],\n",
    "                                unmatched_airports_df.set_index(\"CITY\").loc[unmatched_cities[unmatched_cities == 1].index],\n",
    "                                left_index=True,\n",
    "                                right_index=True,\n",
    "                                how=\"left\")\n",
    "\n",
    "matched_by_city_airports_df = by_city_airports_df[[\"Code\", \"IATA_CODE\"]].dropna()\n",
    "\n",
    "# Update the matched_airports_df with the new matched airports.\n",
    "matched_airports_df = pd.concat([matched_airports_df, matched_by_city_airports_df])\n",
    "\n",
    "\n",
    "# Update both datasets of unmatched airport codes.\n",
    "unmatched_numeric_airports_df = unmatched_numeric_airports_df[~unmatched_numeric_airports_df[\"Code\"].isin(matched_by_city_airports_df[\"Code\"].to_list())]\n",
    "unmatched_airports_df = unmatched_airports_df[~unmatched_airports_df[\"IATA_CODE\"].isin(matched_by_city_airports_df[\"IATA_CODE\"].to_list())]\n",
    "\n",
    "print(\"Number of matched airports:\", len(matched_airports_df))\n",
    "print(\"Number of unmatched airports from the month of October:\", len(unmatched_numeric_airports_df))\n",
    "print(\"Number of unmatched airports from the dataset as a whole:\", len(unmatched_airports_df))"
   ],
   "id": "32e0ece8af7e036",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched airports: 278\n",
      "Number of unmatched airports from the month of October: 29\n",
      "Number of unmatched airports from the dataset as a whole: 44\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I will now match airports together if they are the only airport in their state.",
   "id": "8dd17401b55fa1c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.649586Z",
     "start_time": "2025-05-14T15:18:00.621231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gather how many times each city occurs in both dataframes.\n",
    "unmatched_numeric_states = unmatched_numeric_airports_df[\"N_STATE\"].value_counts()\n",
    "unmatched_states = unmatched_airports_df[\"STATE\"].value_counts()\n",
    "\n",
    "# Finding when the State occurs only once in both unmatched_numeric_airports_df (DOT) and unmatched_airports_df (IATA).\n",
    "by_state_airports_df = pd.merge(unmatched_numeric_airports_df.set_index(\"N_STATE\").loc[unmatched_numeric_states[unmatched_numeric_states ==1].index],\n",
    "                                unmatched_airports_df.set_index(\"STATE\").loc[unmatched_states[unmatched_states == 1].index],\n",
    "                                left_index=True,\n",
    "                                right_index=True,\n",
    "                                how=\"left\")\n",
    "\n",
    "matched_by_state_airports_df = by_state_airports_df[[\"Code\", \"IATA_CODE\"]].dropna()\n",
    "\n",
    "# Update the matched_airports_df with the new matched airports.\n",
    "matched_airports_df = pd.concat([matched_airports_df, matched_by_state_airports_df])\n",
    "\n",
    "# Update both datasets of unmatched airport codes.\n",
    "unmatched_airports_df = unmatched_airports_df[~unmatched_airports_df[\"IATA_CODE\"].isin(matched_by_state_airports_df[\"IATA_CODE\"].to_list())]\n",
    "unmatched_numeric_airports_df = unmatched_numeric_airports_df[~unmatched_numeric_airports_df[\"Code\"].isin(matched_by_state_airports_df[\"Code\"].to_list())]\n",
    "\n",
    "print(\"Number of matched airports:\", len(matched_airports_df))\n",
    "print(\"Number of unmatched airports from the month of October:\", len(unmatched_numeric_airports_df))\n",
    "print(\"Number of unmatched airports from the dataset as a whole:\", len(unmatched_airports_df))"
   ],
   "id": "82a817fe424deac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched airports: 291\n",
      "Number of unmatched airports from the month of October: 16\n",
      "Number of unmatched airports from the dataset as a whole: 31\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I will now manually match the final 16 airports.",
   "id": "fded9a020055c058"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.728181Z",
     "start_time": "2025-05-14T15:18:00.716535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The key in the dictionary is the index of the airport in unmatched_numeric_airports_df.\n",
    "codes ={216: \"SAN\",\n",
    "        297: \"MVY\",\n",
    "        153: \"EWN\",\n",
    "        154: \"OAJ\",\n",
    "        177: \"FAY\",\n",
    "        92: \"JFK\",\n",
    "        107: \"LGA\",\n",
    "        265: \"SWF\",\n",
    "        130: \"RDM\",\n",
    "        296: \"OTH\",\n",
    "        17: \"IAH\",\n",
    "        26: \"HOU\",\n",
    "        49: \"CLL\",\n",
    "        52: \"MAF\",\n",
    "        64: \"MFE\",\n",
    "        241: \"SGU\"}\n",
    "\n",
    "# Add the codes to an unmatched dataframe.\n",
    "unmatched_numeric_airports_df[\"IATA_CODE\"] = \"\"\n",
    "unmatched_numeric_airports_df.loc[codes.keys(), \"IATA_CODE\"] = list(codes.values())\n",
    "\n",
    "# Add the airports and the codes to the matched dataframe.\n",
    "matched_airports_df = pd.concat([matched_airports_df, unmatched_numeric_airports_df[[\"Code\", \"IATA_CODE\"]]])\n",
    "\n",
    "print(f\"I have now matched {len(matched_airports_df)} of {len(numeric_airports_df)} airports\")"
   ],
   "id": "4716e97569a8af9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have now matched 307 of 307 airports\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:00.806136Z",
     "start_time": "2025-05-14T15:18:00.793330Z"
    }
   },
   "cell_type": "code",
   "source": "matched_airports_df.head()",
   "id": "1da13699fc2d8896",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Code IATA_CODE\n",
       "1  14771       SFO\n",
       "3  12892       LAX\n",
       "4  14869       SLC\n",
       "5  10299       ANC\n",
       "6  11292       DEN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>IATA_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14771</td>\n",
       "      <td>SFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14869</td>\n",
       "      <td>SLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10299</td>\n",
       "      <td>ANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I will now edit flights_df to replace the DOT codes with the IATA airport codes.",
   "id": "f6f6023c6b90dd80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:09.049076Z",
     "start_time": "2025-05-14T15:18:00.934156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for c in [\"ORIGIN\", \"DESTINATION\"]:\n",
    "\n",
    "    # Renaming the columns of matched_airports_df to match those of flights_df.\n",
    "    matched_airports_df.columns=[f\"{c}_AIRPORT\", f\"{c}_IATA_CODE\"]\n",
    "\n",
    "    # Merge the dataframes to add a new column with the correct IATA codes.\n",
    "    flights_df = pd.merge(flights_df, matched_airports_df, on=f\"{c}_AIRPORT\", how=\"left\")\n",
    "\n",
    "    # Replace the DOT codes with the IATA codes.\n",
    "    flights_df.loc[flights_df[\"MONTH\"] == 10, f\"{c}_AIRPORT\"] = flights_df[f\"{c}_IATA_CODE\"]\n",
    "\n",
    "    # Drop the added column.\n",
    "    flights_df = flights_df.drop(f\"{c}_IATA_CODE\", axis=1)\n",
    "\n",
    "    # Check to see if there were any unedited columns.\n",
    "    print(\"There are\", flights_df[f\"{c}_AIRPORT\"].str.contains(r\"\\d+\", regex=True).sum(), f\"airports in the \\\"{c}_AIRPORT\\\" column with a DOT code.\")"
   ],
   "id": "d1255ffe46726242",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 airports in the \"ORIGIN_AIRPORT\" column with a DOT code.\n",
      "There are 0 airports in the \"DESTINATION_AIRPORT\" column with a DOT code.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 3: The Time Columns\n",
    "Many of the columns in flights_df deal with time and these all need to be made machine-friendly."
   ],
   "id": "46592256df1c134a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:09.235984Z",
     "start_time": "2025-05-14T15:18:09.208619Z"
    }
   },
   "cell_type": "code",
   "source": "flights_df.head()",
   "id": "8101605226667fc4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0  2015      1    1            4      AS            98      N407AS   \n",
       "1  2015      1    1            4      AA          2336      N3KUAA   \n",
       "2  2015      1    1            4      US           840      N171US   \n",
       "3  2015      1    1            4      AA           258      N3HYAA   \n",
       "4  2015      1    1            4      AS           135      N527AS   \n",
       "\n",
       "  ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  ARRIVAL_TIME  \\\n",
       "0            ANC                 SEA                    5  ...         408.0   \n",
       "1            LAX                 PBI                   10  ...         741.0   \n",
       "2            SFO                 CLT                   20  ...         811.0   \n",
       "3            LAX                 MIA                   20  ...         756.0   \n",
       "4            SEA                 ANC                   25  ...         259.0   \n",
       "\n",
       "   ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "0          -22.0         0          0                  NaN               NaN   \n",
       "1           -9.0         0          0                  NaN               NaN   \n",
       "2            5.0         0          0                  NaN               NaN   \n",
       "3           -9.0         0          0                  NaN               NaN   \n",
       "4          -21.0         0          0                  NaN               NaN   \n",
       "\n",
       "   SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \n",
       "0             NaN            NaN                  NaN            NaN  \n",
       "1             NaN            NaN                  NaN            NaN  \n",
       "2             NaN            NaN                  NaN            NaN  \n",
       "3             NaN            NaN                  NaN            NaN  \n",
       "4             NaN            NaN                  NaN            NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>98</td>\n",
       "      <td>N407AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2336</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>PBI</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>840</td>\n",
       "      <td>N171US</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CLT</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>811.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>258</td>\n",
       "      <td>N3HYAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>135</td>\n",
       "      <td>N527AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For data that is recorded in minutes, such as TAXI_IN taking 10 minutes, and being recorded as 10, I will leave those columns as is:\n",
    "- DEPARTURE_DELAY\n",
    "- TAXI_OUT\n",
    "- SCHEDULED_TIME\n",
    "- ELAPSED_TIME\n",
    "- AIR_TIME\n",
    "- TAXI_IN\n",
    "- ARRIVAL_DELAY\n",
    "\n",
    "<br>\n",
    "\n",
    "For data that is formated as hhmm, such as WHEELS_ON happening at 08:21, but being recorded as 821, I will turn these columns into pd.datetime, but there are several problems:\n",
    "\n",
    "The columns:\n",
    "- YEAR\n",
    "- MONTH\n",
    "- DAY\n",
    "- DAY_OF_WEEK\n",
    "\n",
    "are accurate only for SCHEDULED_DEPARTURE and for none of the other 5 recorded times:\n",
    "- DEPARTURE_TIME\n",
    "- WHEELS_OFF\n",
    "- WHEELS_ON\n",
    "- SCHEDULED_ARRIVAL\n",
    "- ARRIVAL_TIME\n",
    "\n",
    "If we look at the first row, the SCHEDULED_DEPARTURE is 00:05 on the 1st of January and the DEPARTURE_TIME is 23:54.  If I was to use the YEAR, MONTH, and DAY columns, to calculate datetime, the flight would be shown as departing on the 1st of January 2015 at 23:54 rather than the 31st of December 2014 at 23:54.\n",
    "\n",
    "So, in order to find an accurate datetime for all the time columns, I will use the columns recorded in minutes such as DEPARTURE_DELAY to calculate them.\n",
    "\n",
    "However, 3 of these columns are related to the destination airport:\n",
    "- WHEELS_ON\n",
    "- SCHEDULED_ARRIVAL\n",
    "- ARRIVAL TIME\n",
    "\n",
    "and they are recorded, in flights_df, in the timezone of the destination airport rather than the origin airport.\n",
    "\n",
    "In order to retain data for the destination timezone, I will extract the hour and minute from SCHEDULED_ARRIVAL but ensure that all columns in datetime are in the timezone of the origin airport."
   ],
   "id": "bc77e715ef73e8c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:27.209771Z",
     "start_time": "2025-05-14T15:18:09.387674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Converting SCHEDULED_DEPARTURE from hhmm into datetime and\n",
    "flights_df[\"SCHEDULED_DEPARTURE\"] = flights_df[\"SCHEDULED_DEPARTURE\"].astype(str).str.zfill(4) # Increasing the total number of digits to 4.\n",
    "flights_df[\"HOURS\"] = flights_df[\"SCHEDULED_DEPARTURE\"].str[:2].astype(\"uint8\") # Creating the HOURS column.\n",
    "flights_df[\"MINUTES\"] = flights_df[\"SCHEDULED_DEPARTURE\"].str[2:].astype(\"uint8\") # Creating the MINUTES column.\n",
    "flights_df[\"SCHEDULED_DEPARTURE\"] = pd.to_datetime(flights_df[[\"YEAR\", \"MONTH\", \"DAY\", \"HOURS\", \"MINUTES\"]]) # Transforming SCHEDULED_DEPARTURE into datetime.\n",
    "\n",
    "# Adding separate HOUR and MINUTE columns for departure.\n",
    "flights_df = flights_df.rename({\"HOURS\":\"SCHEDULED_DEPARTURE_HOURS\",\n",
    "                                \"MINUTES\":\"SCHEDULED_DEPARTURE_MINUTES\"}, axis=1)\n",
    "\n",
    "# Adding separate HOUR and MINUTE columns, in the destination timezone, for arrival.\n",
    "flights_df[\"SCHEDULED_ARRIVAL\"] = flights_df[\"SCHEDULED_ARRIVAL\"].astype(str).str.zfill(4) # Increasing the total number of digits to 4.\n",
    "flights_df[\"SCHEDULED_ARRIVAL_HOUR_IN_DESTINATION_TIMEZONE\"] = flights_df[\"SCHEDULED_ARRIVAL\"].str[:2].astype(\"uint8\") # Creating the HOURS column.\n",
    "flights_df[\"SCHEDULED_ARRIVAL_MINUTE_IN_DESTINATION_TIMEZONE\"] = flights_df[\"SCHEDULED_ARRIVAL\"].str[2:].astype(\"uint8\") # Creating the MINUTES column."
   ],
   "id": "b7faa9a7c1a36d83",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating datetime columns for the 5 other times using the features that are recorded in minutes.",
   "id": "ca70ec4d9333792f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:28.895942Z",
     "start_time": "2025-05-14T15:18:27.496407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculating DEPARTURE_TIME from SCHEDULED_DEPARTURE and DEPARTURE_DELAY\n",
    "flights_df[\"DEPARTURE_TIME\"] = flights_df[\"SCHEDULED_DEPARTURE\"] + pd.to_timedelta(flights_df[\"DEPARTURE_DELAY\"], unit=\"m\")\n",
    "\n",
    "# Calculating WHEELS_OFF from DEPARTURE_TIME and TAXI_OUT\n",
    "flights_df[\"WHEELS_OFF\"] = flights_df[\"DEPARTURE_TIME\"] + pd.to_timedelta(flights_df[\"TAXI_OUT\"], unit=\"m\")\n",
    "\n",
    "# Calculating WHEELS_ON from WHEELS_OFF and AIR_TIME\n",
    "flights_df[\"WHEELS_ON\"] = flights_df[\"WHEELS_OFF\"] + pd.to_timedelta(flights_df[\"AIR_TIME\"], unit=\"m\")\n",
    "\n",
    "# Calculating ARRIVAL_TIME from WHEELS_ON and TAXI_IN\n",
    "flights_df[\"ARRIVAL_TIME\"] = flights_df[\"WHEELS_ON\"] + pd.to_timedelta(flights_df[\"TAXI_IN\"], unit=\"m\")\n",
    "\n",
    "# Calculating SCHEDULED_ARRIVAL from SCHEDULED_DEPARTURE and SCHEDULED_TIME\n",
    "flights_df[\"SCHEDULED_ARRIVAL\"] = flights_df[\"SCHEDULED_DEPARTURE\"] + pd.to_timedelta(flights_df[\"SCHEDULED_TIME\"], unit=\"m\")"
   ],
   "id": "3727d1343477eff8",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 4: Cleaning the Data\n",
    "\n",
    "After preparing the time columns and fixing the heterogeneous identifiers of the airports, I will now clean the rest of the data.\n",
    "\n",
    "Flights_df includes flights that have been cancelled and diverted as well as the ones that actually landed at the target airport.\n",
    "\n",
    "In order to predict flight delays, I will only be using flights that have landed at the target airports."
   ],
   "id": "f506db1ef07fc84a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:31.062851Z",
     "start_time": "2025-05-14T15:18:29.009288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dropping rows of flights that were cancelled or diverted.\n",
    "landed_df = flights_df.loc[(flights_df[\"CANCELLED\"] == 0) & (flights_df[\"DIVERTED\"] == 0)]\n",
    "\n",
    "print(f\"{(1 - len(landed_df)/len(flights_df)) * 100:.2f}% of flights, out of a possible {len(flights_df):,} were diverted or cancelled.\")\n",
    "\n",
    "# Dropping the columns related to cancelled flights, diverted flights, as well as the YEAR column.\n",
    "landed_df = landed_df.drop([\"YEAR\", \"DIVERTED\", \"CANCELLED\", \"CANCELLATION_REASON\"], axis=1)"
   ],
   "id": "2ea0540fae479c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81% of flights, out of a possible 5,819,079 were diverted or cancelled.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The:\n",
    "- AIR_SYSTEM_DELAY\n",
    "- SECURITY_DELAY\n",
    "- AIRLINE_DELAY\n",
    "- LATE_AIRCRAFT_DELAY\n",
    "- WEATHER_DELAY\n",
    "\n",
    "columns are all NaN when there is not a delay, but if there is any named delay the other 4 columns will all be 0 rather than NaN."
   ],
   "id": "e38965cbc5338f09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:31.529789Z",
     "start_time": "2025-05-14T15:18:31.126887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Turning the NaNs in these columns into 0s.\n",
    "landed_df.loc[:,[\"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\"]] = \\\n",
    "    landed_df.loc[:,[\"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\"]].fillna(0.0)"
   ],
   "id": "6d8bb40f9b4d7e8d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:32.309610Z",
     "start_time": "2025-05-14T15:18:31.610428Z"
    }
   },
   "cell_type": "code",
   "source": "landed_df.isna().sum()",
   "id": "c8fc9805621fbbff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTH                                               0\n",
       "DAY                                                 0\n",
       "DAY_OF_WEEK                                         0\n",
       "AIRLINE                                             0\n",
       "FLIGHT_NUMBER                                       0\n",
       "TAIL_NUMBER                                         0\n",
       "ORIGIN_AIRPORT                                      0\n",
       "DESTINATION_AIRPORT                                 0\n",
       "SCHEDULED_DEPARTURE                                 0\n",
       "DEPARTURE_TIME                                      0\n",
       "DEPARTURE_DELAY                                     0\n",
       "TAXI_OUT                                            0\n",
       "WHEELS_OFF                                          0\n",
       "SCHEDULED_TIME                                      0\n",
       "ELAPSED_TIME                                        0\n",
       "AIR_TIME                                            0\n",
       "DISTANCE                                            0\n",
       "WHEELS_ON                                           0\n",
       "TAXI_IN                                             0\n",
       "SCHEDULED_ARRIVAL                                   0\n",
       "ARRIVAL_TIME                                        0\n",
       "ARRIVAL_DELAY                                       0\n",
       "AIR_SYSTEM_DELAY                                    0\n",
       "SECURITY_DELAY                                      0\n",
       "AIRLINE_DELAY                                       0\n",
       "LATE_AIRCRAFT_DELAY                                 0\n",
       "WEATHER_DELAY                                       0\n",
       "SCHEDULED_DEPARTURE_HOURS                           0\n",
       "SCHEDULED_DEPARTURE_MINUTES                         0\n",
       "SCHEDULED_ARRIVAL_HOUR_IN_DESTINATION_TIMEZONE      0\n",
       "SCHEDULED_ARRIVAL_MINUTE_IN_DESTINATION_TIMEZONE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:32.448875Z",
     "start_time": "2025-05-14T15:18:32.435501Z"
    }
   },
   "cell_type": "code",
   "source": "landed_df.dtypes",
   "id": "333d992f9fd07a57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTH                                                        uint8\n",
       "DAY                                                          uint8\n",
       "DAY_OF_WEEK                                                  uint8\n",
       "AIRLINE                                                   category\n",
       "FLIGHT_NUMBER                                             category\n",
       "TAIL_NUMBER                                               category\n",
       "ORIGIN_AIRPORT                                              object\n",
       "DESTINATION_AIRPORT                                         object\n",
       "SCHEDULED_DEPARTURE                                 datetime64[ns]\n",
       "DEPARTURE_TIME                                      datetime64[ns]\n",
       "DEPARTURE_DELAY                                            float64\n",
       "TAXI_OUT                                                   float64\n",
       "WHEELS_OFF                                          datetime64[ns]\n",
       "SCHEDULED_TIME                                             float64\n",
       "ELAPSED_TIME                                               float64\n",
       "AIR_TIME                                                   float64\n",
       "DISTANCE                                                     int64\n",
       "WHEELS_ON                                           datetime64[ns]\n",
       "TAXI_IN                                                    float64\n",
       "SCHEDULED_ARRIVAL                                   datetime64[ns]\n",
       "ARRIVAL_TIME                                        datetime64[ns]\n",
       "ARRIVAL_DELAY                                              float64\n",
       "AIR_SYSTEM_DELAY                                           float64\n",
       "SECURITY_DELAY                                             float64\n",
       "AIRLINE_DELAY                                              float64\n",
       "LATE_AIRCRAFT_DELAY                                        float64\n",
       "WEATHER_DELAY                                              float64\n",
       "SCHEDULED_DEPARTURE_HOURS                                    uint8\n",
       "SCHEDULED_DEPARTURE_MINUTES                                  uint8\n",
       "SCHEDULED_ARRIVAL_HOUR_IN_DESTINATION_TIMEZONE               uint8\n",
       "SCHEDULED_ARRIVAL_MINUTE_IN_DESTINATION_TIMEZONE             uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:33.932996Z",
     "start_time": "2025-05-14T15:18:32.637138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "landed_df = landed_df.astype({\"ORIGIN_AIRPORT\":\"category\",\n",
    "                              \"DESTINATION_AIRPORT\":\"category\",\n",
    "                              \"DEPARTURE_DELAY\":\"int16\",\n",
    "                              \"TAXI_OUT\":\"uint16\",\n",
    "                              \"SCHEDULED_TIME\":\"uint16\",\n",
    "                              \"ELAPSED_TIME\":\"uint16\",\n",
    "                              \"AIR_TIME\":\"uint16\",\n",
    "                              \"DISTANCE\":\"uint16\",\n",
    "                              \"TAXI_IN\":\"uint8\",\n",
    "                              \"ARRIVAL_DELAY\":\"int16\",\n",
    "                              \"AIR_SYSTEM_DELAY\":\"uint16\",\n",
    "                              \"SECURITY_DELAY\":\"uint16\",\n",
    "                              \"AIRLINE_DELAY\":\"uint16\",\n",
    "                              \"LATE_AIRCRAFT_DELAY\":\"uint16\",\n",
    "                              \"WEATHER_DELAY\":\"uint16\"})"
   ],
   "id": "80153f2eb63ec8f8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:18:35.297781Z",
     "start_time": "2025-05-14T15:18:34.136936Z"
    }
   },
   "cell_type": "code",
   "source": "landed_df.to_pickle(\"landed_flights.pkl\")",
   "id": "a921b03adff176c8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Further Work\n",
    "\n",
    "In the next notebook, Exploratory_Data_Analysis, I will explore and analyse the data.\n",
    "\n",
    "I will also use the cleaned data from this notebook to predict the arrival delay of each flight in the Flight_Predictions notebook.\n",
    "\n",
    "Further work could be done to clean, and work with, the cancelled and diverted flights, but they are outside the scope of this project."
   ],
   "id": "c1c3530c653b578c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
